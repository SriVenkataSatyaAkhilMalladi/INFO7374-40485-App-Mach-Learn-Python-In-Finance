{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HDm4nm3FWEdU"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.linear_model import Ridge, Lasso\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import statsmodels.api as sm\n",
        "from sklearn.preprocessing import StandardScaler\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uQ1lBLaGWI9T"
      },
      "outputs": [],
      "source": [
        "# Load your dataset\n",
        "data = pd.read_csv('/Meta_Stock_Analysis_Data.csv')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0KXXegUDYyVz"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Assuming your DataFrame is called 'data'\n",
        "\n",
        "# Drop rows where 'Returns' column has null values\n",
        "data.dropna(subset=['Returns'], inplace=True)\n",
        "\n",
        "# Drop rows where 'VolumeMovingAverage_10' column has null values\n",
        "data.dropna(subset=['VolumeMovingAverage_10'], inplace=True)\n",
        "\n",
        "# Drop rows where 'PriceLag_1' column has null values\n",
        "data.dropna(subset=['PriceLag_1'], inplace=True)\n",
        "\n",
        "# Drop rows where 'ReturnLag_1' column has null values\n",
        "data.dropna(subset=['ReturnLag_1'], inplace=True)\n",
        "\n",
        "# Drop rows where 'PriceLag_3' column has null values\n",
        "data.dropna(subset=['PriceLag_3'], inplace=True)\n",
        "\n",
        "# Drop rows where 'ReturnLag_3' column has null values\n",
        "data.dropna(subset=['ReturnLag_3'], inplace=True)\n",
        "\n",
        "# Drop rows where 'PriceLag_5' column has null values\n",
        "data.dropna(subset=['PriceLag_5'], inplace=True)\n",
        "\n",
        "# Drop rows where 'ReturnLag_5' column has null values\n",
        "data.dropna(subset=['ReturnLag_5'], inplace=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o3zBIfoXXm-s"
      },
      "outputs": [],
      "source": [
        "data.drop(\"Date\", axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4VRaDAJ-ZD4H"
      },
      "outputs": [],
      "source": [
        "data['Volatility']=np.log10(data['Volatility'])\n",
        "data['HighLowRange']=np.log10(data['HighLowRange'])\n",
        "data['VolumeMovingAverage_10']=np.log10(data['VolumeMovingAverage_10'])\n",
        "data['UNRATE']=np.log10(data['UNRATE'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wj6KrU0JZ4-Y"
      },
      "outputs": [],
      "source": [
        "columns_to_keep = ['Open','Volume','VolumeChange','Momentum','MovingAverage_50', 'Volatility', 'PriceLag_1','ReturnLag_5', 'Close']\n",
        "\n",
        "# Assuming your DataFrame is named 'df'\n",
        "data = data[columns_to_keep].reset_index(drop=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "VRtpTs5weA-a",
        "outputId": "22b96ea5-986e-4165-c114-0aa1b765e266"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        Open    Volume  VolumeChange   Momentum  MovingAverage_50  Volatility  \\\n",
              "0  28.889999  41855500     -0.625082        NaN               NaN    0.069421   \n",
              "1  27.200001  35230300     -0.158287 -11.330000               NaN   -0.093306   \n",
              "2  26.700001  42473400      0.205593  -8.159998               NaN    0.127105   \n",
              "3  26.070000  61489200      0.447711  -4.190001               NaN    0.041393   \n",
              "4  27.000000  26159500     -0.574568  -5.690001               NaN   -0.096910   \n",
              "\n",
              "   PriceLag_1  ReturnLag_5      Close  \n",
              "0   29.600000     0.032187  27.719999  \n",
              "1   27.719999    -0.033909  26.900000  \n",
              "2   26.900000    -0.096208  25.870001  \n",
              "3   25.870001    -0.022538  26.809999  \n",
              "4   26.809999     0.050018  26.309999  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b69d7f42-6cb5-4912-8cf5-806c82bea222\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Open</th>\n",
              "      <th>Volume</th>\n",
              "      <th>VolumeChange</th>\n",
              "      <th>Momentum</th>\n",
              "      <th>MovingAverage_50</th>\n",
              "      <th>Volatility</th>\n",
              "      <th>PriceLag_1</th>\n",
              "      <th>ReturnLag_5</th>\n",
              "      <th>Close</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>28.889999</td>\n",
              "      <td>41855500</td>\n",
              "      <td>-0.625082</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.069421</td>\n",
              "      <td>29.600000</td>\n",
              "      <td>0.032187</td>\n",
              "      <td>27.719999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>27.200001</td>\n",
              "      <td>35230300</td>\n",
              "      <td>-0.158287</td>\n",
              "      <td>-11.330000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.093306</td>\n",
              "      <td>27.719999</td>\n",
              "      <td>-0.033909</td>\n",
              "      <td>26.900000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>26.700001</td>\n",
              "      <td>42473400</td>\n",
              "      <td>0.205593</td>\n",
              "      <td>-8.159998</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.127105</td>\n",
              "      <td>26.900000</td>\n",
              "      <td>-0.096208</td>\n",
              "      <td>25.870001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>26.070000</td>\n",
              "      <td>61489200</td>\n",
              "      <td>0.447711</td>\n",
              "      <td>-4.190001</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.041393</td>\n",
              "      <td>25.870001</td>\n",
              "      <td>-0.022538</td>\n",
              "      <td>26.809999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>27.000000</td>\n",
              "      <td>26159500</td>\n",
              "      <td>-0.574568</td>\n",
              "      <td>-5.690001</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.096910</td>\n",
              "      <td>26.809999</td>\n",
              "      <td>0.050018</td>\n",
              "      <td>26.309999</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b69d7f42-6cb5-4912-8cf5-806c82bea222')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b69d7f42-6cb5-4912-8cf5-806c82bea222 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b69d7f42-6cb5-4912-8cf5-806c82bea222');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#scaled_value = (original_value - mean) / std\n",
        "row_data = data['Open']\n",
        "\n",
        "row_mean = np.mean(row_data)\n",
        "row_std = np.std(row_data)\n",
        "print(row_mean,row_std)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DTsxYN1eeCHv",
        "outputId": "4da5b7a1-13b5-411f-f097-820ffae34b45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "149.29798540417613 85.88414893602835\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b7g3FnkRRGyK"
      },
      "outputs": [],
      "source": [
        "scaler = StandardScaler()\n",
        "scaled_data = scaler.fit_transform(data)\n",
        "data = pd.DataFrame(scaled_data, columns=data.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nZVCoBzbZUDL"
      },
      "outputs": [],
      "source": [
        "#Since we are getting an error suggesting nans or infs or out of range nums exist.\n",
        "#since we know no nulls are present we are trying to remove any infs if present.\n",
        "data.replace([np.inf, -np.inf], np.nan)\n",
        "\n",
        "data.dropna(inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WSliZ9WrWMWj"
      },
      "outputs": [],
      "source": [
        "# Split the data into features (X) and target variable (y)\n",
        "input = data.drop('Close', axis=1)\n",
        "output = data['Close']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(input, output, test_size=0.2, random_state=42)\n",
        "X = X_train\n",
        "y = y_train\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "id": "Pw68sb_AWRD1",
        "outputId": "7a824374-333b-4249-f6e8-087f66bfec1c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
              "             colsample_bylevel=None, colsample_bynode=None,\n",
              "             colsample_bytree=None, early_stopping_rounds=None,\n",
              "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
              "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
              "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
              "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
              "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
              "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
              "             predictor=None, random_state=None, ...)"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
              "             colsample_bylevel=None, colsample_bynode=None,\n",
              "             colsample_bytree=None, early_stopping_rounds=None,\n",
              "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
              "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
              "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
              "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
              "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
              "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
              "             predictor=None, random_state=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
              "             colsample_bylevel=None, colsample_bynode=None,\n",
              "             colsample_bytree=None, early_stopping_rounds=None,\n",
              "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
              "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
              "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
              "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
              "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
              "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
              "             predictor=None, random_state=None, ...)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ],
      "source": [
        "# Ridge regression\n",
        "ridge = Ridge(alpha=1.0)\n",
        "ridge.fit(X_train, y_train)\n",
        "\n",
        "# LASSO\n",
        "lasso = Lasso(alpha=1.0)\n",
        "lasso.fit(X_train, y_train)\n",
        "\n",
        "# Random Forest\n",
        "rf = RandomForestRegressor()\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "# XGBoost\n",
        "xgboost = xgb.XGBRegressor()\n",
        "xgboost.fit(X_train, y_train)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qYY7xVR2WWXo"
      },
      "outputs": [],
      "source": [
        "# Feature importance using Ridge regression\n",
        "ridge_feature_importance = np.abs(ridge.coef_)\n",
        "\n",
        "# Feature importance using LASSO\n",
        "lasso_feature_importance = np.abs(lasso.coef_)\n",
        "\n",
        "# Feature importance using Random Forest\n",
        "rf_feature_importance = rf.feature_importances_\n",
        "\n",
        "# Feature importance using XGBoost\n",
        "xgboost_feature_importance = xgboost.feature_importances_\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "OG-Pch1jWekB",
        "outputId": "5124b4f7-d22b-4f3e-adf1-d62d15b9fc12"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Plot feature importance using Ridge regression\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x=ridge_feature_importance, y=X.columns)\n",
        "plt.title('Ridge Regression Feature Importance')\n",
        "plt.xlabel('Importance')\n",
        "plt.ylabel('Features')\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iuTJFI46WiYr",
        "outputId": "7d456c25-78ad-4f34-fb29-574914c9bf84"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                            OLS Regression Results                            \n",
            "==============================================================================\n",
            "Dep. Variable:                  Close   R-squared:                       0.999\n",
            "Model:                            OLS   Adj. R-squared:                  0.999\n",
            "Method:                 Least Squares   F-statistic:                 2.534e+05\n",
            "Date:                Fri, 30 Jun 2023   Prob (F-statistic):               0.00\n",
            "Time:                        23:14:59   Log-Likelihood:                 4370.7\n",
            "No. Observations:                2164   AIC:                            -8723.\n",
            "Df Residuals:                    2155   BIC:                            -8672.\n",
            "Df Model:                           8                                         \n",
            "Covariance Type:            nonrobust                                         \n",
            "====================================================================================\n",
            "                       coef    std err          t      P>|t|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------------\n",
            "const                0.0012      0.001      1.722      0.085      -0.000       0.003\n",
            "Open                 0.9397      0.020     46.331      0.000       0.900       0.979\n",
            "Volume           -2.508e-05      0.001     -0.027      0.978      -0.002       0.002\n",
            "VolumeChange         0.0005      0.001      0.704      0.482      -0.001       0.002\n",
            "Momentum             0.0163      0.001     17.147      0.000       0.014       0.018\n",
            "MovingAverage_50     0.0657      0.005     12.542      0.000       0.055       0.076\n",
            "Volatility          -0.0006      0.001     -0.490      0.625      -0.003       0.002\n",
            "PriceLag_1          -0.0060      0.020     -0.301      0.764      -0.045       0.033\n",
            "ReturnLag_5         -0.0030      0.001     -4.166      0.000      -0.004      -0.002\n",
            "==============================================================================\n",
            "Omnibus:                      232.341   Durbin-Watson:                   2.015\n",
            "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             1956.234\n",
            "Skew:                           0.047   Prob(JB):                         0.00\n",
            "Kurtosis:                       7.657   Cond. No.                         78.4\n",
            "==============================================================================\n",
            "\n",
            "Notes:\n",
            "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
          ]
        }
      ],
      "source": [
        "# OLS table for Ridge regression\n",
        "X_train_ols = sm.add_constant(X_train)\n",
        "ridge_ols = sm.OLS(y_train, X_train_ols).fit()\n",
        "print(ridge_ols.summary())\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FJbd0zF3Wjyz",
        "outputId": "512a7e2c-a5b2-4203-99e2-be63a7f354d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                            OLS Regression Results                            \n",
            "==============================================================================\n",
            "Dep. Variable:                  Close   R-squared:                       0.999\n",
            "Model:                            OLS   Adj. R-squared:                  0.999\n",
            "Method:                 Least Squares   F-statistic:                 2.534e+05\n",
            "Date:                Fri, 30 Jun 2023   Prob (F-statistic):               0.00\n",
            "Time:                        23:14:59   Log-Likelihood:                 4370.7\n",
            "No. Observations:                2164   AIC:                            -8723.\n",
            "Df Residuals:                    2155   BIC:                            -8672.\n",
            "Df Model:                           8                                         \n",
            "Covariance Type:            nonrobust                                         \n",
            "====================================================================================\n",
            "                       coef    std err          t      P>|t|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------------\n",
            "const                0.0012      0.001      1.722      0.085      -0.000       0.003\n",
            "Open                 0.9397      0.020     46.331      0.000       0.900       0.979\n",
            "Volume           -2.508e-05      0.001     -0.027      0.978      -0.002       0.002\n",
            "VolumeChange         0.0005      0.001      0.704      0.482      -0.001       0.002\n",
            "Momentum             0.0163      0.001     17.147      0.000       0.014       0.018\n",
            "MovingAverage_50     0.0657      0.005     12.542      0.000       0.055       0.076\n",
            "Volatility          -0.0006      0.001     -0.490      0.625      -0.003       0.002\n",
            "PriceLag_1          -0.0060      0.020     -0.301      0.764      -0.045       0.033\n",
            "ReturnLag_5         -0.0030      0.001     -4.166      0.000      -0.004      -0.002\n",
            "==============================================================================\n",
            "Omnibus:                      232.341   Durbin-Watson:                   2.015\n",
            "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             1956.234\n",
            "Skew:                           0.047   Prob(JB):                         0.00\n",
            "Kurtosis:                       7.657   Cond. No.                         78.4\n",
            "==============================================================================\n",
            "\n",
            "Notes:\n",
            "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
          ]
        }
      ],
      "source": [
        "# OLS table for LASSO\n",
        "X_train_ols = sm.add_constant(X_train)\n",
        "lasso_ols = sm.OLS(y_train, X_train_ols).fit()\n",
        "print(lasso_ols.summary())\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "95MV6gV_WlAw"
      },
      "outputs": [],
      "source": [
        "# Perform feature selection using Ridge regression\n",
        "threshold = 0.1\n",
        "selected_features_ridge = X.columns[ridge_feature_importance > threshold]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tbqyu2cBWnXJ"
      },
      "outputs": [],
      "source": [
        "# Perform feature selection using LASSO\n",
        "selected_features_lasso = X.columns[lasso_feature_importance > threshold]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4GnxMoEtWofR",
        "outputId": "a314cc16-6ec7-44b7-c381-4207569c776c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Selected Features (Ridge Regression):\n",
            "Index(['Open', 'PriceLag_1'], dtype='object')\n",
            "\n",
            "Selected Features (LASSO):\n",
            "Index([], dtype='object')\n"
          ]
        }
      ],
      "source": [
        "# Print the selected features\n",
        "print(\"Selected Features (Ridge Regression):\")\n",
        "print(selected_features_ridge)\n",
        "print()\n",
        "\n",
        "print(\"Selected Features (LASSO):\")\n",
        "print(selected_features_lasso)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "oDDrnMYiejMx",
        "outputId": "daf56311-6a35-4f49-929f-3dacf9a9d96a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ridge Regression - Best Hyperparameters:  {'alpha': 0.01, 'fit_intercept': False, 'solver': 'lsqr'}\n",
            "Ridge Regression - Best Score:  0.9989086518799141\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.linear_model import Ridge, Lasso, ElasticNet\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from xgboost import XGBRegressor\n",
        "\n",
        "# Define the parameter grids for each model\n",
        "ridge_params = {'alpha': [0.01, 0.1, 1.0, 10.0, 100.0],\n",
        "                'fit_intercept': [True, False],\n",
        "                'solver': ['auto', 'svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga']}\n",
        "lasso_params = {'alpha': [0.01, 0.1, 1.0, 10.0, 100.0],\n",
        "                'fit_intercept': [True, False],\n",
        "                'selection': ['cyclic', 'random']}\n",
        "elasticnet_params = {'alpha': [0.01, 0.1, 1.0, 10.0, 100.0],\n",
        "                     'l1_ratio': [0.2, 0.5, 0.8],\n",
        "                     'fit_intercept': [True, False],\n",
        "                     'selection': ['cyclic', 'random']}\n",
        "\n",
        "rf_params = {'n_estimators': [100, 200, 300, 400],\n",
        "             'max_depth': [None, 5, 10, 15],\n",
        "             'min_samples_split': [2, 5, 10],\n",
        "             'min_samples_leaf': [1, 2, 4]}\n",
        "xgb_params = {'n_estimators': [100, 200, 300, 400],\n",
        "              'max_depth': [3, 5, 7],\n",
        "              'learning_rate': [0.1, 0.01, 0.001],\n",
        "              'subsample': [0.6, 0.8, 1.0],\n",
        "              'colsample_bytree': [0.6, 0.8, 1.0]}\n",
        "\n",
        "# Create the models\n",
        "ridge = Ridge()\n",
        "lasso = Lasso()\n",
        "elasticnet = ElasticNet()\n",
        "rf = RandomForestRegressor()\n",
        "xgb = XGBRegressor()\n",
        "\n",
        "# Perform grid search with cross-validation for each model\n",
        "ridge_grid = GridSearchCV(ridge, ridge_params, cv=5)\n",
        "ridge_grid.fit(X, y)\n",
        "\n",
        "\n",
        "\n",
        "# Print the best hyperparameters and best scores for each model\n",
        "print(\"Ridge Regression - Best Hyperparameters: \", ridge_grid.best_params_)\n",
        "print(\"Ridge Regression - Best Score: \", ridge_grid.best_score_)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "_OHhRoOdfL77",
        "outputId": "497231b3-fedd-46a5-9423-37f5b2eb809e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.232e-01, tolerance: 1.696e-01\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.008e-01, tolerance: 1.671e-01\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.198e-01, tolerance: 1.712e-01\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.698e-01, tolerance: 1.671e-01\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.716e-01, tolerance: 1.597e-01\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.781e-01, tolerance: 1.697e-01\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.471e-01, tolerance: 1.597e-01\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.528e-01, tolerance: 1.712e-01\n",
            "  model = cd_fast.enet_coordinate_descent(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Lasso Regression - Best Hyperparameters:  {'alpha': 0.01, 'fit_intercept': False, 'selection': 'cyclic'}\n",
            "Lasso Regression - Best Score:  0.9986657588825374\n"
          ]
        }
      ],
      "source": [
        "lasso_grid = GridSearchCV(lasso, lasso_params, cv=5)\n",
        "lasso_grid.fit(X, y)\n",
        "\n",
        "print(\"Lasso Regression - Best Hyperparameters: \", lasso_grid.best_params_)\n",
        "print(\"Lasso Regression - Best Score: \", lasso_grid.best_score_)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vO2jnv1uf-Au",
        "outputId": "31859c8d-4590-4ae4-f6ca-5b571355596a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.769e-01, tolerance: 1.726e-01\n",
            "  model = cd_fast.enet_coordinate_descent(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ElasticNet Regression - Best Hyperparameters:  {'alpha': 0.01, 'fit_intercept': False, 'l1_ratio': 0.8, 'selection': 'cyclic'}\n",
            "ElasticNet Regression - Best Score:  0.9985916690505828\n"
          ]
        }
      ],
      "source": [
        "elasticnet_grid = GridSearchCV(elasticnet, elasticnet_params, cv=5)\n",
        "elasticnet_grid.fit(X, y)\n",
        "\n",
        "print(\"ElasticNet Regression - Best Hyperparameters: \", elasticnet_grid.best_params_)\n",
        "print(\"ElasticNet Regression - Best Score: \", elasticnet_grid.best_score_)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "6VUfpzkmgAjQ",
        "outputId": "a1b1aa18-9231-47a6-e28a-6a6c644a7bd5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Random Forest - Best Hyperparameters:  {'max_depth': 15, 'min_samples_leaf': 4, 'min_samples_split': 10, 'n_estimators': 100}\n",
            "Random Forest - Best Score:  0.9986097263126708\n"
          ]
        }
      ],
      "source": [
        "rf_grid = GridSearchCV(rf, rf_params, cv=5)\n",
        "rf_grid.fit(X, y)\n",
        "\n",
        "\n",
        "print(\"Random Forest - Best Hyperparameters: \", rf_grid.best_params_)\n",
        "print(\"Random Forest - Best Score: \", rf_grid.best_score_)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ljtpodk9gC0C"
      },
      "outputs": [],
      "source": [
        "xgb_grid = GridSearchCV(xgb, xgb_params, cv=5)\n",
        "xgb_grid.fit(X, y)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rtEpx2Q7YDeX",
        "outputId": "ae8cee74-8aeb-4338-bec0-b511c1e37a13"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "XGBoost - Best Hyperparameters:  {'colsample_bytree': 1.0, 'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 200, 'subsample': 0.6}\n",
            "XGBoost - Best Score:  0.998768125019262\n"
          ]
        }
      ],
      "source": [
        "print(\"XGBoost - Best Hyperparameters: \", xgb_grid.best_params_)\n",
        "print(\"XGBoost - Best Score: \", xgb_grid.best_score_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dd1d_paOsRcv",
        "outputId": "3cff000b-2ae8-4f1d-97d3-1251ab4c7a00"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ridge Regression - RMSE:  0.032124690527866075\n",
            "Lasso Regression - RMSE:  0.034204857526220545\n",
            "ElasticNet Regression - RMSE:  0.03584818966770281\n",
            "Random Forest - RMSE:  0.03461735372128882\n",
            "XGBoost - RMSE:  0.03244177606028449\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "from math import sqrt\n",
        "\n",
        "# Create the models with the best hyperparameters\n",
        "ridge = Ridge(alpha=0.01, fit_intercept=False, solver='lsqr')\n",
        "lasso = Lasso(alpha=0.01, fit_intercept=False, selection='cyclic')\n",
        "elasticnet = ElasticNet(alpha=0.01, fit_intercept=False, l1_ratio=0.8, selection='cyclic')\n",
        "rf = RandomForestRegressor(max_depth=15, min_samples_leaf=4, min_samples_split=5, n_estimators=100)\n",
        "xgb = XGBRegressor(colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.6)\n",
        "\n",
        "# Fit the models with the training data\n",
        "ridge.fit(X, y)\n",
        "lasso.fit(X, y)\n",
        "elasticnet.fit(X, y)\n",
        "rf.fit(X, y)\n",
        "xgb.fit(X, y)\n",
        "\n",
        "# Perform predictions on the test data\n",
        "ridge_predictions = ridge.predict(X_test)\n",
        "lasso_predictions = lasso.predict(X_test)\n",
        "elasticnet_predictions = elasticnet.predict(X_test)\n",
        "rf_predictions = rf.predict(X_test)\n",
        "xgb_predictions = xgb.predict(X_test)\n",
        "\n",
        "# Calculate RMSE\n",
        "ridge_rmse = sqrt(mean_squared_error(y_test, ridge_predictions))\n",
        "lasso_rmse = sqrt(mean_squared_error(y_test, lasso_predictions))\n",
        "elasticnet_rmse = sqrt(mean_squared_error(y_test, elasticnet_predictions))\n",
        "rf_rmse = sqrt(mean_squared_error(y_test, rf_predictions))\n",
        "xgb_rmse = sqrt(mean_squared_error(y_test, xgb_predictions))\n",
        "\n",
        "# Print the RMSE for each model\n",
        "\n",
        "print(\"Ridge Regression - RMSE: \", ridge_rmse)\n",
        "\n",
        "print(\"Lasso Regression - RMSE: \", lasso_rmse)\n",
        "\n",
        "print(\"ElasticNet Regression - RMSE: \", elasticnet_rmse)\n",
        "\n",
        "print(\"Random Forest - RMSE: \", rf_rmse)\n",
        "\n",
        "print(\"XGBoost - RMSE: \", xgb_rmse)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lFnTiwxBjjLl",
        "outputId": "1aa88713-f335-4665-ca84-3c89e3b8e3f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Smoothed States:\n",
            "[279.06830313  41.7859335  -15.31875931 ...   0.63606913   0.9355784\n",
            "   1.06865605]\n",
            "One-Step Prediction:\n",
            "1.1850249891069333\n"
          ]
        }
      ],
      "source": [
        "#Kalman filter\n",
        "import numpy as np\n",
        "from numpy import transpose, array\n",
        "from numpy.linalg import inv\n",
        "\n",
        "\n",
        "param0=[1.5, 1.5]\n",
        "\n",
        "def kf_train(Y):\n",
        "    Y = np.array(Y)\n",
        "    Y = transpose(array(Y))\n",
        "    T = Y.shape[0]\n",
        "\n",
        "\n",
        "    # initial values\n",
        "    x_init = np.array([[280], [0.03]]) # two states: stock price, percentage change in stock price\n",
        "    P_init = 900 * np.eye(len(x_init))\n",
        "\n",
        "    # 2x2 identity matrix\n",
        "    Idn = np.eye(2)\n",
        "\n",
        "    # allocate result matrices\n",
        "    x_predict = np.zeros((T, 2, 1))      # prediction of state vector\n",
        "    P_predict = np.zeros((T, 2, 2))  # prediction error covariance matrix\n",
        "    x_update = np.zeros((T, 2, 1))       # estimation of state vector\n",
        "    P_update = np.zeros((T, 2, 2))   # estimation error covariance matrix\n",
        "\n",
        "\n",
        "    K = np.zeros((T, 2, 1))       # Kalman Gain\n",
        "    v = np.zeros((T, 1, 1))  # error of estimate\n",
        "    F = np.zeros((T, 1, 1))\n",
        "\n",
        "    # initial x\n",
        "    x_update[0] = x_init\n",
        "    P_update[0] = P_init\n",
        "    x_predict[0] = x_init\n",
        "    P_predict[0] = P_init\n",
        "\n",
        "    q= param0[0]\n",
        "    r= param0[1]\n",
        "\n",
        "    # matrices\n",
        "    t = 1\n",
        "    A = array([[1, t], [0, 1]])\n",
        "    Q = q*array([[1, 0], [0, 1]])\n",
        "    H = array([1, 0])\n",
        "    H.shape = (1, 2)\n",
        "    R = r*np.eye(1)\n",
        "    v = np.zeros((T, 1, 1))\n",
        "\n",
        "    for i in range(T):\n",
        "        # prediction stage\n",
        "        if i > 0:\n",
        "            x_predict[i] = A @ x_update[i-1]\n",
        "            P_predict[i] = A @ P_update[i-1] @ transpose(A) + Q\n",
        "\n",
        "        # estimation stage\n",
        "        v[i] = Y[i] - H @ A @ x_update[i-1]\n",
        "        F[i] = H @ P_predict[i] @ transpose(H) + R\n",
        "\n",
        "        K[i] = P_predict[i] @ transpose(H) @ inv((H @ P_predict[i] @ transpose(H)) + R)\n",
        "\n",
        "        x_update[i] = x_predict[i] + K[i] @ v[i]\n",
        "        P_update[i] = (Idn - K[i] @ H) @ P_predict[i]\n",
        "\n",
        "    \"smoother\"\n",
        "    L = np.zeros((T,2,2))\n",
        "\n",
        "    x_smooth = np.zeros((T, 2, 1))\n",
        "    P_smooth = np.zeros((T, 2, 2))\n",
        "\n",
        "    x_smooth[T-1] = x_update[T-1]\n",
        "    P_smooth[T-1] = P_update[T-1]\n",
        "\n",
        "\n",
        "    for t in range(T-1,0,-1): #range(start, stop, step)\n",
        "        L[t-1] = P_update[t-1] @ transpose(A) @ inv(P_predict[t-1])\n",
        "        x_smooth[t-1] = x_update[t-1] + L[t-1] @ (x_smooth[t]-A @ x_update[t])\n",
        "        P_smooth[t-1] = P_update[t-1] + L[t-1] @ (P_smooth[t]-P_update[t]) @ transpose(L[t-1])\n",
        "\n",
        "\n",
        "    x_update.shape=(Y.shape[0],2,)\n",
        "    x_smooth.shape=(Y.shape[0],2,)\n",
        "\n",
        "    #one step forward prediction\n",
        "    y_pred = A @ x_smooth[T-1]\n",
        "\n",
        "    return x_smooth[:, 0], y_pred[0]\n",
        "\n",
        "# Assuming your dataset is stored in a variable called 'dataset'\n",
        "\n",
        "# Apply the Kalman Filter\n",
        "# Reshape the input data to have shape (2705,)\n",
        "input_data = data['Close'].values.flatten()\n",
        "\n",
        "# Apply the Kalman Filter\n",
        "smoothed_states, one_step_prediction = kf_train(input_data)\n",
        "\n",
        "# Print the smoothed states and one-step prediction\n",
        "print(\"Smoothed States:\")\n",
        "print(smoothed_states)\n",
        "\n",
        "print(\"One-Step Prediction:\")\n",
        "print(one_step_prediction)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QHFclF_KR7kF"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming your dataset is stored in a variable called 'dataset'\n",
        "\n",
        "# Apply the Kalman Filter\n",
        "# Reshape the input data to have shape (2705,)\n",
        "input_data = dataset['Close'].values.flatten()\n",
        "\n",
        "# Apply the Kalman Filter\n",
        "smoothed_states, one_step_prediction = kf_train(input_data)\n",
        "\n",
        "# Generate x-axis values\n",
        "x = range(len(input_data))\n",
        "\n",
        "# Plot the original data\n",
        "plt.plot(x, input_data, label='Original Data')\n",
        "\n",
        "# Plot the smoothed states\n",
        "plt.plot(x, smoothed_states[:, 0], label='Smoothed States')\n",
        "\n",
        "# Plot the one-step prediction\n",
        "plt.plot(x[-1], one_step_prediction, 'ro', label='One-Step Prediction')\n",
        "\n",
        "# Set plot title and labels\n",
        "plt.title('Kalman Filter')\n",
        "plt.xlabel('Time')\n",
        "plt.ylabel('Value')\n",
        "\n",
        "# Add legend\n",
        "plt.legend()\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "from math import sqrt\n",
        "\n",
        "# Create the models with the best hyperparameters\n",
        "ridge = Ridge(alpha=0.01, fit_intercept=False, solver='lsqr')\n",
        "ridge.fit(X, y)\n",
        "\n",
        "# Perform predictions on the test data\n",
        "ridge_predictions = ridge.predict(X_test)\n",
        "Y_pred = ridge_predictions\n",
        "\n",
        "# Calculate RMSE\n",
        "#ridge_rmse = sqrt(mean_squared_error(y_test, ridge_predictions))\n"
      ],
      "metadata": {
        "id": "Gb12zcmDX5Cp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming you have the variables Close, Y_pred, and Open\n",
        "\n",
        "# Initialize variables\n",
        "positions = []  # List to store trading positions\n",
        "profits_losses = []  # List to store profit/loss values\n",
        "num_rows = X_test.shape[0]\n",
        "print(\"Number of rows in X_test:\", num_rows)\n",
        "\n",
        "# Iterate over the data\n",
        "for i in range(num_rows):\n",
        "    if Y_pred[i] > X_test['Open'].iloc[i]:\n",
        "        # Buy signal\n",
        "        positions.append('Long')\n",
        "        profits_losses.append(y_test.iloc[i] - X_test['Open'].iloc[i])  # Profit/Loss = Close - Open\n",
        "    elif Y_pred[i] < X_test['Open'].iloc[i]:\n",
        "        # Sell signal\n",
        "        positions.append('Short')\n",
        "        profits_losses.append(X_test['Open'].iloc[i] - y_test.iloc[i])  # Profit/Loss = Open - Close\n",
        "    else:\n",
        "        # No signal\n",
        "        positions.append('Hold')\n",
        "        profits_losses.append(0)  # No profit/loss\n",
        "\n",
        "# Calculate total profit/loss\n",
        "total_profit_loss = sum(profits_losses)\n",
        "\n",
        "# Print results\n",
        "for i in range(num_rows):\n",
        "    print(f\"Position: {positions[i]} | Profit/Loss: {profits_losses[i]}\")\n",
        "\n",
        "print(f\"Total Profit/Loss: {total_profit_loss}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wSp0cHRjYeIK",
        "outputId": "d8c8ec8f-7631-46f6-b579-0377c781de65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of rows in X_test: 541\n",
            "Position: Long | Profit/Loss: -0.005321806112878635\n",
            "Position: Long | Profit/Loss: 0.025309480947935725\n",
            "Position: Long | Profit/Loss: -0.015344624122340722\n",
            "Position: Short | Profit/Loss: 0.015283468528255906\n",
            "Position: Short | Profit/Loss: 0.0016233034177151606\n",
            "Position: Long | Profit/Loss: -0.010466271790383619\n",
            "Position: Short | Profit/Loss: -0.014274050753788958\n",
            "Position: Long | Profit/Loss: -0.005894658878353255\n",
            "Position: Long | Profit/Loss: 0.007069692640521458\n",
            "Position: Short | Profit/Loss: 0.013649419298547905\n",
            "Position: Short | Profit/Loss: 0.0007495750311774518\n",
            "Position: Long | Profit/Loss: -0.006913976072218775\n",
            "Position: Short | Profit/Loss: -0.004881611117207085\n",
            "Position: Short | Profit/Loss: -0.0003263582600120385\n",
            "Position: Long | Profit/Loss: -0.001110887855865439\n",
            "Position: Short | Profit/Loss: -0.002557993264834746\n",
            "Position: Short | Profit/Loss: -0.015382122906621176\n",
            "Position: Short | Profit/Loss: 0.03743709120998617\n",
            "Position: Short | Profit/Loss: 0.0446888909297416\n",
            "Position: Short | Profit/Loss: -0.018646671390687125\n",
            "Position: Long | Profit/Loss: -0.009088088435983077\n",
            "Position: Long | Profit/Loss: 0.012768995700546015\n",
            "Position: Short | Profit/Loss: 0.002376416082421895\n",
            "Position: Short | Profit/Loss: -0.03462585562953224\n",
            "Position: Long | Profit/Loss: 0.036014182626066926\n",
            "Position: Long | Profit/Loss: 0.013525008390811832\n",
            "Position: Short | Profit/Loss: 0.0042399627982441235\n",
            "Position: Long | Profit/Loss: -0.007888663350871628\n",
            "Position: Short | Profit/Loss: 0.02443605857657949\n",
            "Position: Short | Profit/Loss: 0.011323418775781247\n",
            "Position: Short | Profit/Loss: 0.009456341267487178\n",
            "Position: Short | Profit/Loss: 0.044266173358517014\n",
            "Position: Short | Profit/Loss: -0.010608294729290035\n",
            "Position: Short | Profit/Loss: -0.0045386391699422934\n",
            "Position: Long | Profit/Loss: 0.023401761476686822\n",
            "Position: Short | Profit/Loss: -0.018579105391068995\n",
            "Position: Short | Profit/Loss: -0.005373032778024367\n",
            "Position: Short | Profit/Loss: 0.006490951022371294\n",
            "Position: Short | Profit/Loss: -0.017447560291516395\n",
            "Position: Short | Profit/Loss: -0.0363413134628941\n",
            "Position: Long | Profit/Loss: 0.0011606734262511464\n",
            "Position: Short | Profit/Loss: -0.004156426415027781\n",
            "Position: Long | Profit/Loss: -0.0014314643561144647\n",
            "Position: Short | Profit/Loss: -0.016336865985497218\n",
            "Position: Short | Profit/Loss: 0.008653965660701868\n",
            "Position: Long | Profit/Loss: 0.03480686366578922\n",
            "Position: Long | Profit/Loss: 0.00035316589107414753\n",
            "Position: Long | Profit/Loss: -0.15591888208536853\n",
            "Position: Long | Profit/Loss: 0.006919934044643403\n",
            "Position: Short | Profit/Loss: -0.005892287739435426\n",
            "Position: Short | Profit/Loss: 0.028024294369072493\n",
            "Position: Short | Profit/Loss: 0.04768446099285795\n",
            "Position: Short | Profit/Loss: 0.014642354752201547\n",
            "Position: Long | Profit/Loss: -0.0673560260631546\n",
            "Position: Short | Profit/Loss: -0.030750728799379845\n",
            "Position: Short | Profit/Loss: 0.06533092064885526\n",
            "Position: Short | Profit/Loss: 0.0011211897792005043\n",
            "Position: Short | Profit/Loss: -0.006203943765679565\n",
            "Position: Short | Profit/Loss: -0.003672186336538097\n",
            "Position: Short | Profit/Loss: -0.029434898032665746\n",
            "Position: Long | Profit/Loss: -0.03872261176959951\n",
            "Position: Long | Profit/Loss: 0.019942007338216605\n",
            "Position: Short | Profit/Loss: -0.0027670621740891743\n",
            "Position: Short | Profit/Loss: -0.012904594423464366\n",
            "Position: Short | Profit/Loss: 0.009563960264050195\n",
            "Position: Short | Profit/Loss: -0.0197149987860189\n",
            "Position: Short | Profit/Loss: 0.009682537524627444\n",
            "Position: Short | Profit/Loss: -0.0060522815439036926\n",
            "Position: Long | Profit/Loss: -0.007889071932400848\n",
            "Position: Short | Profit/Loss: 0.05012840202868918\n",
            "Position: Short | Profit/Loss: 0.00832864116491877\n",
            "Position: Long | Profit/Loss: 0.002937974455477832\n",
            "Position: Long | Profit/Loss: 0.05953309306728005\n",
            "Position: Short | Profit/Loss: 0.018406799512580285\n",
            "Position: Long | Profit/Loss: 0.021357479159283294\n",
            "Position: Long | Profit/Loss: 0.012252265517237904\n",
            "Position: Long | Profit/Loss: 0.02356612238849798\n",
            "Position: Short | Profit/Loss: -0.008733378611211595\n",
            "Position: Long | Profit/Loss: 0.023607972747819117\n",
            "Position: Long | Profit/Loss: 0.0412188935054586\n",
            "Position: Short | Profit/Loss: 0.033088315047141104\n",
            "Position: Long | Profit/Loss: -0.02264552725354685\n",
            "Position: Short | Profit/Loss: 0.01233372454613435\n",
            "Position: Long | Profit/Loss: 0.011220346715807572\n",
            "Position: Short | Profit/Loss: 0.044813630465769805\n",
            "Position: Short | Profit/Loss: 0.012088875295563906\n",
            "Position: Long | Profit/Loss: -0.0030581949978916168\n",
            "Position: Long | Profit/Loss: -0.012472682421608289\n",
            "Position: Short | Profit/Loss: 0.008706151398726547\n",
            "Position: Short | Profit/Loss: -0.021065456739042365\n",
            "Position: Short | Profit/Loss: 0.005806289820106392\n",
            "Position: Short | Profit/Loss: 0.008115103221216335\n",
            "Position: Short | Profit/Loss: 0.01085343229142044\n",
            "Position: Short | Profit/Loss: -0.062007855607109974\n",
            "Position: Long | Profit/Loss: 0.02133563622484158\n",
            "Position: Short | Profit/Loss: 0.00506558051914574\n",
            "Position: Long | Profit/Loss: -0.0012004340726776697\n",
            "Position: Long | Profit/Loss: -0.01731240273919482\n",
            "Position: Long | Profit/Loss: 0.05239334723217559\n",
            "Position: Short | Profit/Loss: 0.009575726458606493\n",
            "Position: Short | Profit/Loss: 0.0050995848553556655\n",
            "Position: Long | Profit/Loss: 0.011247260391821667\n",
            "Position: Short | Profit/Loss: 0.002272255432621717\n",
            "Position: Short | Profit/Loss: -0.01899669352013106\n",
            "Position: Short | Profit/Loss: 0.0006388042527003535\n",
            "Position: Short | Profit/Loss: 0.013968521811317747\n",
            "Position: Short | Profit/Loss: -0.0117736497237525\n",
            "Position: Short | Profit/Loss: -0.02492126878185591\n",
            "Position: Short | Profit/Loss: -0.0061775127329891655\n",
            "Position: Short | Profit/Loss: -0.0033970812191545033\n",
            "Position: Long | Profit/Loss: 0.010172874630886286\n",
            "Position: Long | Profit/Loss: -0.028104062919856787\n",
            "Position: Long | Profit/Loss: -0.018431378831287315\n",
            "Position: Short | Profit/Loss: -0.006849839058845397\n",
            "Position: Short | Profit/Loss: 0.10967660920644251\n",
            "Position: Short | Profit/Loss: -0.04338412446387663\n",
            "Position: Short | Profit/Loss: 0.03171660197780743\n",
            "Position: Short | Profit/Loss: 0.1270644162054863\n",
            "Position: Short | Profit/Loss: 0.039749964251727166\n",
            "Position: Short | Profit/Loss: 0.005878818263635344\n",
            "Position: Short | Profit/Loss: 0.0047220868831980845\n",
            "Position: Long | Profit/Loss: -0.0030940539093911035\n",
            "Position: Short | Profit/Loss: 0.004172773646634931\n",
            "Position: Long | Profit/Loss: 0.040859129171397335\n",
            "Position: Short | Profit/Loss: 0.015895627941706847\n",
            "Position: Long | Profit/Loss: 0.03230332313871992\n",
            "Position: Short | Profit/Loss: 0.0014900560138610512\n",
            "Position: Short | Profit/Loss: 0.00029783240455533155\n",
            "Position: Short | Profit/Loss: -0.04627031480899424\n",
            "Position: Long | Profit/Loss: 0.01648872038098359\n",
            "Position: Short | Profit/Loss: 0.02567633959283583\n",
            "Position: Long | Profit/Loss: -0.006315477020367943\n",
            "Position: Short | Profit/Loss: -0.0039052842150597566\n",
            "Position: Short | Profit/Loss: 0.04423411435176533\n",
            "Position: Long | Profit/Loss: -0.0027138240655701917\n",
            "Position: Long | Profit/Loss: 0.004280637946181054\n",
            "Position: Long | Profit/Loss: 0.020411515203902553\n",
            "Position: Long | Profit/Loss: 0.006477821303818354\n",
            "Position: Long | Profit/Loss: 0.04738351182090306\n",
            "Position: Short | Profit/Loss: -0.04108729260749444\n",
            "Position: Short | Profit/Loss: -0.010805203134949204\n",
            "Position: Short | Profit/Loss: 0.020687704188929956\n",
            "Position: Long | Profit/Loss: 0.08927988446098789\n",
            "Position: Short | Profit/Loss: -0.03094405673724432\n",
            "Position: Short | Profit/Loss: 0.037000933127955715\n",
            "Position: Short | Profit/Loss: 0.014277077557928397\n",
            "Position: Long | Profit/Loss: -0.0004388451644117275\n",
            "Position: Long | Profit/Loss: -0.0071606977108864545\n",
            "Position: Long | Profit/Loss: 0.0069145938353958325\n",
            "Position: Long | Profit/Loss: -0.026909826348367014\n",
            "Position: Short | Profit/Loss: -0.021120306649727416\n",
            "Position: Long | Profit/Loss: 0.01977697314371507\n",
            "Position: Short | Profit/Loss: -0.031846684221003674\n",
            "Position: Short | Profit/Loss: 0.08755021403858132\n",
            "Position: Long | Profit/Loss: 0.0967162128871395\n",
            "Position: Long | Profit/Loss: 0.002173335098753837\n",
            "Position: Short | Profit/Loss: -0.051528960994718265\n",
            "Position: Long | Profit/Loss: -0.027774262011510786\n",
            "Position: Short | Profit/Loss: -0.0128209922784604\n",
            "Position: Short | Profit/Loss: -0.12524578472491332\n",
            "Position: Long | Profit/Loss: 0.0005405490739066598\n",
            "Position: Long | Profit/Loss: 0.010041907716471954\n",
            "Position: Long | Profit/Loss: 0.10103816454311976\n",
            "Position: Short | Profit/Loss: -0.011988119823066773\n",
            "Position: Long | Profit/Loss: 0.03089849214077167\n",
            "Position: Long | Profit/Loss: -0.0011458264009826039\n",
            "Position: Short | Profit/Loss: 0.015309681415745707\n",
            "Position: Long | Profit/Loss: 0.0017391336319935585\n",
            "Position: Short | Profit/Loss: -0.019989427576045937\n",
            "Position: Long | Profit/Loss: -0.021926417543137233\n",
            "Position: Short | Profit/Loss: -0.008001032641927752\n",
            "Position: Short | Profit/Loss: 0.008349555983930002\n",
            "Position: Short | Profit/Loss: -0.039998477583588765\n",
            "Position: Long | Profit/Loss: -0.005508347129300706\n",
            "Position: Short | Profit/Loss: -0.03343243662717699\n",
            "Position: Short | Profit/Loss: -0.04038113477975275\n",
            "Position: Long | Profit/Loss: 0.0023894059792419764\n",
            "Position: Short | Profit/Loss: 0.008415981855879717\n",
            "Position: Short | Profit/Loss: -0.013588570787912646\n",
            "Position: Short | Profit/Loss: -0.001997097395415034\n",
            "Position: Short | Profit/Loss: 0.00035643586706504693\n",
            "Position: Short | Profit/Loss: -0.014211727459992884\n",
            "Position: Long | Profit/Loss: 0.05159974248101751\n",
            "Position: Short | Profit/Loss: -0.006926568251644727\n",
            "Position: Short | Profit/Loss: -0.009798892207016685\n",
            "Position: Short | Profit/Loss: 0.01590122766826818\n",
            "Position: Short | Profit/Loss: -0.010555019671265098\n",
            "Position: Short | Profit/Loss: 0.008743210789847966\n",
            "Position: Short | Profit/Loss: 0.017832486449857576\n",
            "Position: Long | Profit/Loss: 0.015520887316633203\n",
            "Position: Long | Profit/Loss: -0.0030504583851100886\n",
            "Position: Long | Profit/Loss: 0.0028437869713070496\n",
            "Position: Long | Profit/Loss: 0.0033533112832275502\n",
            "Position: Long | Profit/Loss: 0.0812357311124372\n",
            "Position: Short | Profit/Loss: 0.03135034003627335\n",
            "Position: Short | Profit/Loss: 0.025976209043091725\n",
            "Position: Short | Profit/Loss: 0.006485862526500963\n",
            "Position: Long | Profit/Loss: -0.004390009408573259\n",
            "Position: Short | Profit/Loss: 0.019817865872003182\n",
            "Position: Long | Profit/Loss: -0.005064969735356861\n",
            "Position: Short | Profit/Loss: 0.008828025035808262\n",
            "Position: Long | Profit/Loss: 0.005996592335812956\n",
            "Position: Long | Profit/Loss: 0.06267369867564909\n",
            "Position: Short | Profit/Loss: -0.012540351912668335\n",
            "Position: Long | Profit/Loss: 0.00448265009966109\n",
            "Position: Short | Profit/Loss: 0.010128696547367672\n",
            "Position: Short | Profit/Loss: 0.011169378705013444\n",
            "Position: Short | Profit/Loss: 0.006612401118655464\n",
            "Position: Long | Profit/Loss: -0.0018961324257074086\n",
            "Position: Short | Profit/Loss: -0.005052321173036667\n",
            "Position: Short | Profit/Loss: -0.02365598327447649\n",
            "Position: Short | Profit/Loss: 0.020417296365176252\n",
            "Position: Long | Profit/Loss: 0.011409008098047568\n",
            "Position: Short | Profit/Loss: 0.07873375190827589\n",
            "Position: Long | Profit/Loss: -0.000503552084762271\n",
            "Position: Short | Profit/Loss: 0.04702804103253788\n",
            "Position: Short | Profit/Loss: -0.027198247286482125\n",
            "Position: Short | Profit/Loss: 0.003516741382926014\n",
            "Position: Long | Profit/Loss: -0.022524867790393976\n",
            "Position: Short | Profit/Loss: -0.0054288499819843405\n",
            "Position: Short | Profit/Loss: 0.003176344068239939\n",
            "Position: Long | Profit/Loss: -0.007743072033430165\n",
            "Position: Short | Profit/Loss: -0.04973666682232647\n",
            "Position: Short | Profit/Loss: 0.09638141022055935\n",
            "Position: Short | Profit/Loss: 0.004246428378929204\n",
            "Position: Long | Profit/Loss: 0.0182373448537706\n",
            "Position: Short | Profit/Loss: 0.0036674845970019465\n",
            "Position: Long | Profit/Loss: 0.008818197943744499\n",
            "Position: Long | Profit/Loss: 0.002058639581210553\n",
            "Position: Short | Profit/Loss: 0.008279206673153516\n",
            "Position: Long | Profit/Loss: 0.010847098617572826\n",
            "Position: Short | Profit/Loss: 0.0034223917176934293\n",
            "Position: Long | Profit/Loss: 0.020413293004178268\n",
            "Position: Long | Profit/Loss: -0.010161793723617668\n",
            "Position: Long | Profit/Loss: 0.019207346194504524\n",
            "Position: Short | Profit/Loss: -0.009731384424247591\n",
            "Position: Long | Profit/Loss: -0.005480272799590791\n",
            "Position: Short | Profit/Loss: 0.00850712106960616\n",
            "Position: Short | Profit/Loss: -0.03083150358310338\n",
            "Position: Short | Profit/Loss: 0.009304243949786684\n",
            "Position: Long | Profit/Loss: 0.0012356699927531523\n",
            "Position: Short | Profit/Loss: -0.008930631928320998\n",
            "Position: Short | Profit/Loss: 0.00758277626273246\n",
            "Position: Short | Profit/Loss: 0.016306497425791017\n",
            "Position: Long | Profit/Loss: -0.041853828848975816\n",
            "Position: Short | Profit/Loss: 0.01698880288234439\n",
            "Position: Short | Profit/Loss: -0.013912045479065216\n",
            "Position: Long | Profit/Loss: 0.006345175150855198\n",
            "Position: Short | Profit/Loss: 0.00040427980154555954\n",
            "Position: Long | Profit/Loss: 0.06053300671429196\n",
            "Position: Short | Profit/Loss: 0.0031547020831386163\n",
            "Position: Short | Profit/Loss: 0.007662464802187796\n",
            "Position: Short | Profit/Loss: 0.004466855666897862\n",
            "Position: Long | Profit/Loss: 0.07305302342278797\n",
            "Position: Short | Profit/Loss: -0.011363810020001086\n",
            "Position: Short | Profit/Loss: 0.14541039979399217\n",
            "Position: Short | Profit/Loss: -0.009754242367258747\n",
            "Position: Short | Profit/Loss: 0.02412820820157957\n",
            "Position: Long | Profit/Loss: 0.0013361060017758053\n",
            "Position: Long | Profit/Loss: -0.01582877629236701\n",
            "Position: Long | Profit/Loss: 0.010632181531616602\n",
            "Position: Long | Profit/Loss: 0.007009672778523435\n",
            "Position: Long | Profit/Loss: 0.021732050458932783\n",
            "Position: Short | Profit/Loss: -0.02176422423966795\n",
            "Position: Short | Profit/Loss: -0.0025893756664960854\n",
            "Position: Short | Profit/Loss: 0.007089620121352613\n",
            "Position: Long | Profit/Loss: -0.013079849550862166\n",
            "Position: Short | Profit/Loss: 0.0005262978653921419\n",
            "Position: Short | Profit/Loss: 0.013787110072852826\n",
            "Position: Short | Profit/Loss: 0.017774941690639257\n",
            "Position: Long | Profit/Loss: 0.008626564750160659\n",
            "Position: Short | Profit/Loss: 0.015250970369864558\n",
            "Position: Short | Profit/Loss: -0.0776601651221634\n",
            "Position: Long | Profit/Loss: 0.005960435236718298\n",
            "Position: Long | Profit/Loss: 0.004720454270157548\n",
            "Position: Long | Profit/Loss: -0.015010635124681926\n",
            "Position: Short | Profit/Loss: 0.05384312532496627\n",
            "Position: Short | Profit/Loss: -0.006524207646435576\n",
            "Position: Long | Profit/Loss: 0.010146887145416505\n",
            "Position: Short | Profit/Loss: -0.006227352117226248\n",
            "Position: Long | Profit/Loss: 0.021801802133832426\n",
            "Position: Short | Profit/Loss: 0.006438592134108245\n",
            "Position: Long | Profit/Loss: 0.0053239925331661775\n",
            "Position: Short | Profit/Loss: -0.0439839942455178\n",
            "Position: Short | Profit/Loss: -0.026418822758649374\n",
            "Position: Long | Profit/Loss: 0.010944395293836173\n",
            "Position: Long | Profit/Loss: -0.02661250042195107\n",
            "Position: Short | Profit/Loss: 0.012587684894542983\n",
            "Position: Short | Profit/Loss: 0.002199486163150799\n",
            "Position: Short | Profit/Loss: -0.0027695925422509537\n",
            "Position: Long | Profit/Loss: -0.00505039232549942\n",
            "Position: Long | Profit/Loss: 0.02315773375369118\n",
            "Position: Short | Profit/Loss: 0.023775467956911545\n",
            "Position: Short | Profit/Loss: 0.0028937163295642554\n",
            "Position: Long | Profit/Loss: -0.029913768721896827\n",
            "Position: Long | Profit/Loss: -0.02149518258257752\n",
            "Position: Short | Profit/Loss: 0.07170416284707765\n",
            "Position: Short | Profit/Loss: 0.012485029259218128\n",
            "Position: Short | Profit/Loss: -0.018346560462330852\n",
            "Position: Short | Profit/Loss: 0.0019175855905650963\n",
            "Position: Short | Profit/Loss: -0.018289027476810105\n",
            "Position: Long | Profit/Loss: 0.005729842008648456\n",
            "Position: Short | Profit/Loss: -0.017650369991590142\n",
            "Position: Short | Profit/Loss: 0.019912678548560492\n",
            "Position: Short | Profit/Loss: 0.028828105893815792\n",
            "Position: Short | Profit/Loss: -0.0027135631581577946\n",
            "Position: Short | Profit/Loss: -0.06598882017859631\n",
            "Position: Long | Profit/Loss: -0.007167759920544192\n",
            "Position: Short | Profit/Loss: 0.023577812175701984\n",
            "Position: Short | Profit/Loss: 0.0042446283624975045\n",
            "Position: Short | Profit/Loss: 0.06693547422292134\n",
            "Position: Long | Profit/Loss: -0.01428509205084888\n",
            "Position: Short | Profit/Loss: 0.0009588386440018137\n",
            "Position: Long | Profit/Loss: 0.0020413747164687024\n",
            "Position: Long | Profit/Loss: 0.07290755158305795\n",
            "Position: Long | Profit/Loss: 0.05755319489312227\n",
            "Position: Long | Profit/Loss: -0.0025629425378840553\n",
            "Position: Short | Profit/Loss: 0.030250112239723126\n",
            "Position: Short | Profit/Loss: 0.0044497909314429596\n",
            "Position: Long | Profit/Loss: 0.010734160195192965\n",
            "Position: Short | Profit/Loss: 0.008315405881951454\n",
            "Position: Short | Profit/Loss: -0.03597177953967845\n",
            "Position: Long | Profit/Loss: 0.005534630638813209\n",
            "Position: Short | Profit/Loss: -0.02659005043902729\n",
            "Position: Long | Profit/Loss: -0.006023692857445306\n",
            "Position: Short | Profit/Loss: 0.0003271936113069529\n",
            "Position: Short | Profit/Loss: -0.01224098196600576\n",
            "Position: Long | Profit/Loss: -0.06897484291654132\n",
            "Position: Short | Profit/Loss: 0.006785230181620916\n",
            "Position: Short | Profit/Loss: 0.0007062994812051804\n",
            "Position: Short | Profit/Loss: -0.004838277303786276\n",
            "Position: Long | Profit/Loss: -0.029718999486234632\n",
            "Position: Long | Profit/Loss: -0.00934536877463571\n",
            "Position: Long | Profit/Loss: 0.03503814772780886\n",
            "Position: Short | Profit/Loss: 0.018578954734417952\n",
            "Position: Long | Profit/Loss: 0.036340203889802414\n",
            "Position: Long | Profit/Loss: 0.04019695386579142\n",
            "Position: Long | Profit/Loss: 0.0011190907350917545\n",
            "Position: Short | Profit/Loss: 0.0035390153843677385\n",
            "Position: Short | Profit/Loss: 0.02380967228215669\n",
            "Position: Short | Profit/Loss: -0.02131951148000144\n",
            "Position: Short | Profit/Loss: -0.010524578274889063\n",
            "Position: Long | Profit/Loss: -0.003519592408620431\n",
            "Position: Short | Profit/Loss: 0.018050420642431675\n",
            "Position: Long | Profit/Loss: 0.014556316400686664\n",
            "Position: Long | Profit/Loss: -0.0005624725157471477\n",
            "Position: Short | Profit/Loss: -0.0809581149972749\n",
            "Position: Short | Profit/Loss: 0.0068301869690712835\n",
            "Position: Short | Profit/Loss: -0.0014525096378493196\n",
            "Position: Long | Profit/Loss: -0.005792773885270663\n",
            "Position: Short | Profit/Loss: -0.05720693756182915\n",
            "Position: Long | Profit/Loss: 0.008432188973140242\n",
            "Position: Short | Profit/Loss: -0.010805568209261152\n",
            "Position: Long | Profit/Loss: -0.027088707999372685\n",
            "Position: Long | Profit/Loss: 0.019473613659774514\n",
            "Position: Short | Profit/Loss: -0.02717430448118452\n",
            "Position: Short | Profit/Loss: -0.047143217084872235\n",
            "Position: Short | Profit/Loss: 0.0341241430896031\n",
            "Position: Short | Profit/Loss: -0.014530909121129698\n",
            "Position: Long | Profit/Loss: -0.005395839773920885\n",
            "Position: Long | Profit/Loss: 0.05119204028457908\n",
            "Position: Short | Profit/Loss: -0.005494567530855993\n",
            "Position: Short | Profit/Loss: -0.005525876042694611\n",
            "Position: Short | Profit/Loss: -0.01566651610218117\n",
            "Position: Short | Profit/Loss: -0.01735792895350379\n",
            "Position: Short | Profit/Loss: 0.0032096232450553597\n",
            "Position: Short | Profit/Loss: -0.019157945239849872\n",
            "Position: Short | Profit/Loss: -0.0423935033527556\n",
            "Position: Long | Profit/Loss: -4.3155527786886694e-05\n",
            "Position: Short | Profit/Loss: -0.03027490645913078\n",
            "Position: Long | Profit/Loss: -0.023108708714534715\n",
            "Position: Short | Profit/Loss: -0.0054471210718989305\n",
            "Position: Short | Profit/Loss: 0.018261019214835028\n",
            "Position: Long | Profit/Loss: 0.0012487226899269288\n",
            "Position: Short | Profit/Loss: 0.004441849102801987\n",
            "Position: Long | Profit/Loss: 0.004104913155894785\n",
            "Position: Short | Profit/Loss: -0.023256247836054372\n",
            "Position: Short | Profit/Loss: 0.010280902892554011\n",
            "Position: Short | Profit/Loss: -0.027173571568596677\n",
            "Position: Long | Profit/Loss: -0.007671421592799356\n",
            "Position: Long | Profit/Loss: 0.05746481685620708\n",
            "Position: Short | Profit/Loss: 0.03744764102081133\n",
            "Position: Long | Profit/Loss: 0.0049690332636109225\n",
            "Position: Short | Profit/Loss: 0.012445009642945704\n",
            "Position: Short | Profit/Loss: 0.05935885401936525\n",
            "Position: Short | Profit/Loss: -0.030205079324922307\n",
            "Position: Short | Profit/Loss: -0.013212278936111349\n",
            "Position: Long | Profit/Loss: -0.012381469009258406\n",
            "Position: Short | Profit/Loss: 0.005181965229744068\n",
            "Position: Long | Profit/Loss: 0.024829964966461948\n",
            "Position: Long | Profit/Loss: 0.01830857120714019\n",
            "Position: Long | Profit/Loss: -0.016486711256879616\n",
            "Position: Short | Profit/Loss: -0.004309937825140553\n",
            "Position: Long | Profit/Loss: -0.006002558292681204\n",
            "Position: Long | Profit/Loss: -0.006293088514258582\n",
            "Position: Short | Profit/Loss: -0.0170005263302222\n",
            "Position: Short | Profit/Loss: -1.4281187550535535e-05\n",
            "Position: Short | Profit/Loss: 0.00040476843323666856\n",
            "Position: Long | Profit/Loss: -0.013719378961036366\n",
            "Position: Long | Profit/Loss: 0.07336718824128496\n",
            "Position: Long | Profit/Loss: -0.04312803443981872\n",
            "Position: Short | Profit/Loss: 0.026771114068840696\n",
            "Position: Long | Profit/Loss: 0.036059468186756094\n",
            "Position: Long | Profit/Loss: -0.012874759595452645\n",
            "Position: Short | Profit/Loss: 0.005905475397103215\n",
            "Position: Long | Profit/Loss: -0.0013971613640333391\n",
            "Position: Short | Profit/Loss: -0.03181778512378164\n",
            "Position: Short | Profit/Loss: -0.022131794876022348\n",
            "Position: Short | Profit/Loss: 0.030861420921938443\n",
            "Position: Short | Profit/Loss: -0.011178378568904135\n",
            "Position: Short | Profit/Loss: -0.002591929663793291\n",
            "Position: Long | Profit/Loss: -0.023793093644979557\n",
            "Position: Long | Profit/Loss: -0.004041614664273552\n",
            "Position: Long | Profit/Loss: -0.0014074519001369135\n",
            "Position: Short | Profit/Loss: -0.03680498673337777\n",
            "Position: Short | Profit/Loss: -0.023635466879382894\n",
            "Position: Long | Profit/Loss: 0.04089410679708427\n",
            "Position: Short | Profit/Loss: 0.04826795316840382\n",
            "Position: Long | Profit/Loss: 0.009861680932742423\n",
            "Position: Short | Profit/Loss: 0.015001554799991712\n",
            "Position: Long | Profit/Loss: 0.03804449988688863\n",
            "Position: Long | Profit/Loss: 0.07811712279233565\n",
            "Position: Long | Profit/Loss: 0.008344992010185903\n",
            "Position: Short | Profit/Loss: -0.012174124320531776\n",
            "Position: Short | Profit/Loss: -0.012771821461273841\n",
            "Position: Long | Profit/Loss: 0.031139397637292482\n",
            "Position: Long | Profit/Loss: 0.04431468464133603\n",
            "Position: Short | Profit/Loss: 0.060299646641451266\n",
            "Position: Short | Profit/Loss: 0.0034192142336033626\n",
            "Position: Long | Profit/Loss: -0.0215225487223476\n",
            "Position: Short | Profit/Loss: 0.03372250082417927\n",
            "Position: Long | Profit/Loss: 0.0057961497101721715\n",
            "Position: Long | Profit/Loss: -0.05055464854219638\n",
            "Position: Long | Profit/Loss: 0.011163551069521632\n",
            "Position: Short | Profit/Loss: -0.07881577112339644\n",
            "Position: Short | Profit/Loss: 0.08775534148954184\n",
            "Position: Long | Profit/Loss: -0.030588109083118153\n",
            "Position: Long | Profit/Loss: 0.002823386732177746\n",
            "Position: Short | Profit/Loss: 0.012475183683383406\n",
            "Position: Long | Profit/Loss: 0.0015970385784742636\n",
            "Position: Long | Profit/Loss: -0.008244698972253772\n",
            "Position: Long | Profit/Loss: -0.03744415670255785\n",
            "Position: Long | Profit/Loss: -0.03064615422442518\n",
            "Position: Long | Profit/Loss: -0.023606469595861934\n",
            "Position: Long | Profit/Loss: 0.028765827609442962\n",
            "Position: Short | Profit/Loss: -0.04881673111120288\n",
            "Position: Short | Profit/Loss: 0.0060602920907136815\n",
            "Position: Short | Profit/Loss: 0.002402107230484951\n",
            "Position: Short | Profit/Loss: -0.00033026728247442794\n",
            "Position: Short | Profit/Loss: -0.011549448030106668\n",
            "Position: Short | Profit/Loss: -0.05379888058813376\n",
            "Position: Short | Profit/Loss: -0.03988918196370017\n",
            "Position: Long | Profit/Loss: -0.0019145980471522162\n",
            "Position: Short | Profit/Loss: 0.027098773453514746\n",
            "Position: Short | Profit/Loss: 0.015116106160085564\n",
            "Position: Long | Profit/Loss: 0.008317053679243402\n",
            "Position: Long | Profit/Loss: 0.013129046448505544\n",
            "Position: Long | Profit/Loss: 0.026164686562247907\n",
            "Position: Long | Profit/Loss: -0.06521944952682973\n",
            "Position: Short | Profit/Loss: -0.001348036676703357\n",
            "Position: Short | Profit/Loss: 0.01605790501511123\n",
            "Position: Long | Profit/Loss: -0.019489420457029727\n",
            "Position: Short | Profit/Loss: -0.001996687431903732\n",
            "Position: Long | Profit/Loss: -0.05981768196582915\n",
            "Position: Long | Profit/Loss: -0.009616685390036184\n",
            "Position: Long | Profit/Loss: 0.01384723694041018\n",
            "Position: Short | Profit/Loss: 0.006464687265081648\n",
            "Position: Short | Profit/Loss: 0.06915660063963802\n",
            "Position: Short | Profit/Loss: -2.49502581697314e-05\n",
            "Position: Short | Profit/Loss: -0.02089181346040969\n",
            "Position: Long | Profit/Loss: -0.04392420783169673\n",
            "Position: Short | Profit/Loss: 0.004319328560595026\n",
            "Position: Long | Profit/Loss: -0.006297122483847839\n",
            "Position: Long | Profit/Loss: 0.07317654721540068\n",
            "Position: Short | Profit/Loss: -0.010609709715730886\n",
            "Position: Short | Profit/Loss: -0.005149066597411656\n",
            "Position: Long | Profit/Loss: -0.026634478558406116\n",
            "Position: Long | Profit/Loss: 0.08481618958772663\n",
            "Position: Short | Profit/Loss: 0.021223615854351507\n",
            "Position: Long | Profit/Loss: -0.14631177938328443\n",
            "Position: Short | Profit/Loss: 0.05972487429937059\n",
            "Position: Short | Profit/Loss: 0.032097825726709384\n",
            "Position: Long | Profit/Loss: 0.006431325933715759\n",
            "Position: Long | Profit/Loss: -0.02176511774864799\n",
            "Position: Short | Profit/Loss: 0.01130974157721143\n",
            "Position: Short | Profit/Loss: -0.012511106292186103\n",
            "Position: Long | Profit/Loss: -0.002066335646427442\n",
            "Position: Long | Profit/Loss: -0.01177894965474946\n",
            "Position: Long | Profit/Loss: 0.010376506077104386\n",
            "Position: Short | Profit/Loss: -0.0012263860527552684\n",
            "Position: Short | Profit/Loss: 0.011440120892064476\n",
            "Position: Long | Profit/Loss: 0.03864589371352177\n",
            "Position: Short | Profit/Loss: 0.05345908664840593\n",
            "Position: Short | Profit/Loss: -0.01455224289785284\n",
            "Position: Short | Profit/Loss: 0.011292217816247896\n",
            "Position: Long | Profit/Loss: 0.048105512359634506\n",
            "Position: Long | Profit/Loss: -0.003079406841087637\n",
            "Position: Long | Profit/Loss: -0.005745901901262562\n",
            "Position: Short | Profit/Loss: 0.03560441619250565\n",
            "Position: Long | Profit/Loss: 0.04525109460736976\n",
            "Position: Long | Profit/Loss: -0.004827328436912914\n",
            "Position: Short | Profit/Loss: 0.011789707543393702\n",
            "Position: Short | Profit/Loss: -0.06988273367412429\n",
            "Position: Long | Profit/Loss: 0.011206954549155015\n",
            "Position: Long | Profit/Loss: 0.04862807993317397\n",
            "Position: Short | Profit/Loss: 0.10442846250886095\n",
            "Position: Short | Profit/Loss: -0.013709347789011339\n",
            "Position: Short | Profit/Loss: 0.002308053234967966\n",
            "Position: Long | Profit/Loss: 0.013655764335103404\n",
            "Position: Short | Profit/Loss: 0.019551832553317328\n",
            "Position: Short | Profit/Loss: -0.0385688213621852\n",
            "Position: Short | Profit/Loss: -0.007040811063493746\n",
            "Position: Short | Profit/Loss: -0.006389484365558085\n",
            "Position: Short | Profit/Loss: 0.01332482437327398\n",
            "Position: Short | Profit/Loss: -0.05401351912626051\n",
            "Position: Long | Profit/Loss: -0.022593610311952395\n",
            "Position: Long | Profit/Loss: -0.010081975685015065\n",
            "Position: Short | Profit/Loss: 0.022543292968964845\n",
            "Position: Short | Profit/Loss: -0.0030384239127927426\n",
            "Position: Short | Profit/Loss: 0.036210155148574036\n",
            "Position: Short | Profit/Loss: 0.006879576399665854\n",
            "Position: Long | Profit/Loss: -0.0024331029508592797\n",
            "Position: Short | Profit/Loss: -0.0029402880604201265\n",
            "Position: Long | Profit/Loss: -0.1043738700891168\n",
            "Position: Short | Profit/Loss: 0.07443577797668569\n",
            "Position: Short | Profit/Loss: 0.030052914406565545\n",
            "Position: Long | Profit/Loss: -0.03597128283923101\n",
            "Position: Short | Profit/Loss: 0.03550320889322771\n",
            "Position: Long | Profit/Loss: 0.07676531535760589\n",
            "Position: Long | Profit/Loss: 0.022548524895733224\n",
            "Position: Long | Profit/Loss: 0.009344863547494864\n",
            "Position: Short | Profit/Loss: -0.003098453885803265\n",
            "Position: Short | Profit/Loss: -0.0016989150223327698\n",
            "Position: Long | Profit/Loss: 0.006238350636541545\n",
            "Position: Short | Profit/Loss: 0.02011436564115937\n",
            "Position: Short | Profit/Loss: 0.020621707260331856\n",
            "Position: Short | Profit/Loss: -0.005282860517706198\n",
            "Position: Long | Profit/Loss: -0.006246657297974689\n",
            "Position: Long | Profit/Loss: 0.029906643856480786\n",
            "Position: Short | Profit/Loss: 0.06467103118864481\n",
            "Position: Short | Profit/Loss: 0.005766591552357259\n",
            "Total Profit/Loss: 2.02230110893019\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mean = 149.29798540417613\n",
        "std = 85.88414893602835\n",
        "\n",
        "original_value = (total_profit_loss * std) + mean\n",
        "\n",
        "print(original_value)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fhCcn37vesFj",
        "outputId": "8851c70f-7cdb-442b-e430-75b7abcc35e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "322.98159503703187\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}